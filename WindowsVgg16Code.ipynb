{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Feb 19 07:39:43 2023\n",
    "@author: ssegu\n",
    "\n",
    "Modfied Thu Aug 1- 10:45:55 2023\n",
    "edited by Richard Chiu\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import normalize\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if TensorFlow is running on GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "# ... (Same code for loading and preprocessing images and masks)\n",
    "#Load images and masks in order so they match\n",
    "\n",
    "image_directory = r\"c:\\Users\\richch\\Desktop\\ModSOCPristineTiffs\\SOC\"\n",
    "mask_directory = r\"c:\\Users\\richch\\Desktop\\ModSOCPristineTiffs\\MaskSOC\"\n",
    "\n",
    "num_images=500\n",
    "SIZE = 128\n",
    "\n",
    "image_names = glob.glob(r\"c:\\Users\\richch\\Desktop\\ModSOCPristineTiffs\\SOC\\*.tif\")\n",
    "print(image_names)\n",
    "\n",
    "\n",
    "image_names.sort()\n",
    "\n",
    "     \n",
    "\n",
    "image_names_subset = image_names[0:num_images]\n",
    "     \n",
    "\n",
    "images = [cv2.imread(img, 0) for img in image_names_subset]\n",
    "     \n",
    "\n",
    "#image_dataset = np.array(images)\n",
    "#image_dataset = np.expand_dims(image_dataset, axis = 3)\n",
    "image_dataset = np.array([np.repeat(img, 3, axis=-1) for img in images])\n",
    "image_dataset = np.array([np.repeat(img[:, :, np.newaxis], 3, axis=-1) for img in images])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mask_names = glob.glob(r\"c:\\Users\\richch\\Desktop\\ModSOCPristineTiffs\\MaskSOC\\*.tif\")\n",
    "mask_names.sort()\n",
    "mask_names_subset = mask_names[0:num_images]\n",
    "masks = [cv2.imread(mask, 0) for mask in mask_names_subset]\n",
    "mask_dataset = np.array(masks)\n",
    "mask_dataset = np.expand_dims(mask_dataset, axis = 3)\n",
    "\n",
    "\n",
    "print(\"Image data shape is: \", image_dataset.shape)\n",
    "print(\"Mask data shape is: \", mask_dataset.shape)\n",
    "print(\"Max pixel value in image is: \", image_dataset.max())\n",
    "print(\"Labels in the mask are : \", np.unique(mask_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize images\n",
    "image_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler\n",
    "#Do not normalize masks, just rescale to 0 to 1.\n",
    "mask_dataset = mask_dataset /255.  #PIxel values will be 0 or 1\n",
    "     \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.20, random_state = 42)\n",
    "\n",
    "     \n",
    "\n",
    "#Sanity check\n",
    "import random\n",
    "\n",
    "image_number = random.randint(0, len(X_train)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[image_number,:,:,0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_train[image_number,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "     \n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Concatenate, Conv2DTranspose, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Define helper function for the decoder block\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)  # Add batch normalization layer\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = Conv2D(num_filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  # Add batch normalization layer\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Conv2D(num_filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  # Add batch normalization layer\n",
    "    x = Dropout(0.4)(x)  # Add dropout layer\n",
    "\n",
    "    return x\n",
    "\n",
    "# Build the VGG16-based segmentation model\n",
    "def build_vgg16_unet(input_shape, n_classes):\n",
    "    base_model = VGG16(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Encoder part of the architecture (VGG16 model)\n",
    "    s1 = base_model.get_layer(\"block1_conv2\").output   # 64 filters\n",
    "    s1 = Dropout(0.4)(s1)\n",
    "    s2 = base_model.get_layer(\"block2_conv2\").output   # 128 filters\n",
    "    s2 = Dropout(0.4)(s2)\n",
    "    s3 = base_model.get_layer(\"block3_conv3\").output   # 256 filters\n",
    "    s3 = Dropout(0.4)(s3)\n",
    "    s4 = base_model.get_layer(\"block4_conv3\").output   # 512 filters\n",
    "    s4 = Dropout(0.4)(s4)\n",
    "    b1 = base_model.get_layer(\"block5_conv3\").output   # 512 filters\n",
    "\n",
    "    # Decoder part of the architecture\n",
    "    d1 = decoder_block(b1, s4, 512)   # Match number of filters with block4 of encoder\n",
    "    d2 = decoder_block(d1, s3, 256)   # Match number of filters with block3 of encoder\n",
    "    d3 = decoder_block(d2, s2, 128)   # Match number of filters with block2 of encoder\n",
    "    d4 = decoder_block(d3, s1, 64)    # Match number of filters with block1 of encoder\n",
    "\n",
    "    if n_classes == 1:  # Binary\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  # Change the activation based on n_classes\n",
    "    print(activation)\n",
    "\n",
    "    model = Model(base_model.input, outputs, name=\"VGG16_U-Net\")\n",
    "    return model\n",
    "\n",
    "# Instantiate the VGG16-based model and compile it\n",
    "IMG_HEIGHT = image_dataset.shape[1]\n",
    "IMG_WIDTH  = image_dataset.shape[2]\n",
    "IMG_CHANNELS = image_dataset.shape[3]\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "model = build_vgg16_unet(input_shape, n_classes=1)\n",
    "\n",
    "# Freeze the layers of the VGG16 model\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ... (Same code for training, saving, plotting, and evaluating the model)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=100, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False)\n",
    "\n",
    "model.save(r\"c:\\Users\\richch\\Desktop\\VsCode\\SavedModels\\Vgg16_500Datasets_100epochsDropOut3.hdf5\")\n",
    "\n",
    "\n",
    "# Define image and mask data generators with the desired augmentations\n",
    "data_gen_args = dict(rotation_range=20,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     shear_range=0.1,\n",
    "                     zoom_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "def fit_generators(image_datagen, mask_datagen, images, masks, batch_size):\n",
    "    seed = 1\n",
    "    image_generator = image_datagen.flow(images, seed=seed, batch_size=batch_size)\n",
    "    mask_generator = mask_datagen.flow(masks, seed=seed, batch_size=batch_size)\n",
    "    return zip(image_generator, mask_generator)\n",
    "def train_and_visualize(model, images, masks, epochs, batch_size, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold = 0\n",
    "    history_list = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(images, masks):\n",
    "        fold += 1\n",
    "        print(f\"Training fold {fold}\")\n",
    "\n",
    "        X_train, y_train = images[train_index], masks[train_index]\n",
    "        X_val, y_val = images[val_index], masks[val_index]\n",
    "\n",
    "        # Fit generators to the data\n",
    "        train_generator = fit_generators(image_datagen, mask_datagen, X_train, y_train, batch_size)\n",
    "        val_generator = fit_generators(image_datagen, mask_datagen, X_val, y_val, batch_size)\n",
    "\n",
    "        steps_per_epoch = len(X_train) // batch_size\n",
    "        validation_steps = len(X_val) // batch_size\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=val_generator,\n",
    "                            validation_steps=validation_steps,\n",
    "                            shuffle=True)\n",
    "\n",
    "        history_list.append(history)\n",
    "\n",
    "        # Plot the training and validation loss for each fold\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        epochs_range = range(1, len(loss) + 1)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, loss, 'y', label='Training loss')\n",
    "        plt.plot(epochs_range, val_loss, 'r', label='Validation loss')\n",
    "        plt.title(f'Training and validation loss for fold {fold}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot the training and validation accuracy for each fold\n",
    "        acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, acc, 'y', label='Training acc')\n",
    "        plt.plot(epochs_range, val_acc, 'r', label='Validation acc')\n",
    "        plt.title(f'Training and validation accuracy for fold {fold}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    model_save_path = Path(\"\")\n",
    "    model.save(model_save_path)\n",
    "\n",
    "    return history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the modified train_and_visualize function with the entire dataset\n",
    "train_and_visualize(model, image_dataset, mask_dataset, epochs=100, batch_size=16, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(r\"c:\\Users\\richch\\Desktop\\VsCode\\SavedModels\\Vgg16_500Datasets_100epochsDropOut3.hdf5\", compile=False)\n",
    "\n",
    "#X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
    "#y_pred = model.predict(X_test_rgb)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.5\n",
    "     \n",
    "# from tensorflow.keras.metrics import MeanIoU\n",
    "     \n",
    "\n",
    "# n_classes = 2\n",
    "# IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "# IOU_keras.update_state(y_pred_thresholded, y_test)\n",
    "# print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
    "\n",
    "# from sklearn.metrics import jaccard_score\n",
    "\n",
    "\n",
    "\n",
    "# def mean_iou(y_true, y_pred, num_classes=2):\n",
    "#     # Flatten the input\n",
    "#     y_true = tf.reshape(y_true, [-1])\n",
    "#     y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "#     ious = []\n",
    "#     for c in range(num_classes):\n",
    "#         # Convert the scalar to a tensor\n",
    "#         c_tensor = tf.constant(c, dtype=y_true.dtype)\n",
    "        \n",
    "#         # Calculate the true positives, false positives and false negatives\n",
    "#         tp = tf.reduce_sum(tf.cast(tf.equal(y_pred, c_tensor) & tf.equal(y_true, c_tensor), dtype=tf.float32))\n",
    "#         fp = tf.reduce_sum(tf.cast(tf.equal(y_pred, c_tensor) & tf.not_equal(y_true, c_tensor), dtype=tf.float32))\n",
    "#         fn = tf.reduce_sum(tf.cast(tf.not_equal(y_pred, c_tensor) & tf.equal(y_true, c_tensor), dtype=tf.float32))\n",
    "        \n",
    "#         # Calculate IoU for this class and append to the list of IoUs\n",
    "#         iou = tp / (tp + fp + fn + tf.keras.backend.epsilon())  # adding a small constant to avoid division by zero\n",
    "#         ious.append(iou)\n",
    "    \n",
    "#     # Take the mean over all classes\n",
    "#     mean_iou = tf.reduce_mean(ious)\n",
    "#     return mean_iou\n",
    "\n",
    "\n",
    "# Make predictions (assumes your model's output is a binary mask)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.5\n",
    "\n",
    "# # Compute the mean IoU using the custom function\n",
    "# mean_iou_value = mean_iou(y_test, y_pred_thresholded)\n",
    "# print(\"Mean IoU =\", mean_iou_value.numpy())\n",
    "\n",
    "\n",
    "# # Function to compute the intersection over union (IoU) metric\n",
    "\n",
    "# threshold = 0.5\n",
    "# test_img_number = random.randint(0, len(X_test)-1)\n",
    "# test_img = X_test[test_img_number]\n",
    "# ground_truth=y_test[test_img_number]\n",
    "# test_img_input=np.expand_dims(test_img, 0)\n",
    "# prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
    "# print(prediction.shape)\n",
    "\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# plt.subplot(231)\n",
    "# plt.title('Testing Image')\n",
    "# plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "# plt.subplot(232)\n",
    "# plt.title('Testing Label')\n",
    "# plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "# plt.subplot(233)\n",
    "# plt.title('Prediction on test image')\n",
    "# plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# prediction2 = (model.predict(test_img_input)[0,:,:,0])\n",
    "# plt.hist(prediction2.ravel(), bins=50, range=(0, 1))\n",
    "# plt.xlabel(\"Prediction Probability\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Histogram of Prediction Probabilities\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Initialize lists for mean and standard deviation of predictions\n",
    "# mean_predictions = []\n",
    "# std_predictions = []\n",
    "\n",
    "# # Append mean and standard deviation of the predictions\n",
    "# mean_predictions.append(np.mean(prediction))\n",
    "# std_predictions.append(np.std(prediction))\n",
    "\n",
    "# print(\"Mean prediction probability: \", np.mean(mean_predictions))\n",
    "# print(\"Standard deviation of prediction probabilities: \", np.mean(std_predictions))\n",
    "\n",
    "# from sklearn.metrics import precision_recall_curve, roc_curve, auc, confusion_matrix, roc_auc_score\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Flatten ground truth and predictions\n",
    "# y_true_flat = y_test.ravel()\n",
    "# y_pred_flat = (model.predict(X_test).ravel() > 0.5)\n",
    "\n",
    "# # Calculate precision, recall, and thresholds\n",
    "# precision, recall, thresholds_pr = precision_recall_curve(y_true_flat, y_pred_flat)\n",
    "\n",
    "# # Plot Precision-Recall curve\n",
    "# plt.plot(recall, precision)\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Precision-Recall Curve')\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate false positive rate, true positive rate, and thresholds\n",
    "# fpr, tpr, thresholds_roc = roc_curve(y_true_flat, y_pred_flat)\n",
    "# roc_auc = roc_auc_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "# # Plot ROC curve\n",
    "# plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate confusion matrix\n",
    "# cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
    "\n",
    "# # Plot confusion matrix heatmap\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# Calculate the discrepancies between ground truth and prediction\n",
    "discrepancies = ground_truth[:,:,0] - prediction\n",
    "\n",
    "# Visualize the discrepancies\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(132)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.title('Discrepancies (Ground Truth - Prediction)')\n",
    "plt.imshow(discrepancies, cmap='jet')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
